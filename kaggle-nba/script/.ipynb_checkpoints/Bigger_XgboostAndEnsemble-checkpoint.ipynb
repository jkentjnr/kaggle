{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import geopy.distance\n",
    "\n",
    "#package for flattening json in pandas df\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "use_parsed_data = True\n",
    "output_parsed_data_filename = 'parsed_data.csv'\n",
    "\n",
    "calc_last_5_games = True\n",
    "calc_win_loss = True\n",
    "calc_win_loss_write_all = True\n",
    "calc_ratings = True\n",
    "use_team_keys = False\n",
    "use_team_hot_encoding = False\n",
    "use_team_home_away_hot_encoding = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkentjnr/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "output_parsed_data_filename = '../input/parsed_data.csv'\n",
    "\n",
    "calc_last_5_games = True\n",
    "use_team_hot_encoding = False\n",
    "use_team_home_away_hot_encoding = False\n",
    "\n",
    "games = pd.read_csv(output_parsed_data_filename)\n",
    "games = games.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statsColumns = pd.Series(list(games.columns.values))\n",
    "statsColumns = statsColumns.loc[statsColumns.str.startswith(('statsAway', 'statsHome'), na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace any NaN with 0 in the stats\n",
    "games[statsColumns] = games[statsColumns].fillna(value=-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#games['season'] = games['season'].astype('float')\n",
    "games['scoreAway'] = games['scoreAway'].astype('uint8')\n",
    "games['scoreHome'] = games['scoreHome'].astype('uint8')\n",
    "\n",
    "games['statsHome.FgAtt'] = games['statsHome.FgAtt'].astype('uint8')\n",
    "games['statsHome.OffReb'] = games['statsHome.OffReb'].astype('uint8')\n",
    "games['statsHome.Tov'] = games['statsHome.Tov'].astype('uint8')\n",
    "games['statsHome.FtAtt'] = games['statsHome.FtAtt'].astype('uint8')\n",
    "games['statsHome.Pts'] = games['statsHome.Pts'].astype('uint8')\n",
    "\n",
    "games['statsAway.FgAtt'] = games['statsAway.FgAtt'].astype('uint8')\n",
    "games['statsAway.OffReb'] = games['statsAway.OffReb'].astype('uint8')\n",
    "games['statsAway.Tov'] = games['statsAway.Tov'].astype('uint8')\n",
    "games['statsAway.FtAtt'] = games['statsAway.FtAtt'].astype('uint8')\n",
    "games['statsAway.Pts'] = games['statsAway.Pts'].astype('uint8')\n",
    "\n",
    "#scoreQuarters          object\n",
    "#teamAwayCode           object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_team_hot_encoding == True:\n",
    "    homeTeam = pd.get_dummies(games[\"teamHomeCode\"], prefix='team')\n",
    "    awayTeam = pd.get_dummies(games[\"teamAwayCode\"], prefix='team')\n",
    "\n",
    "    homeTeam = homeTeam.replace({0:np.nan})\n",
    "    awayTeam = awayTeam.replace({0:np.nan})\n",
    "\n",
    "    teams = homeTeam.fillna(awayTeam).fillna(0).astype('bool')\n",
    "    # teams[['team_NYK', 'team_CLE', 'team_ATL', 'team_BOS']].head(2)\n",
    "    \n",
    "    games = pd.concat([games, teams], axis=1)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'team_NYK', 'team_CLE']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if use_team_home_away_hot_encoding == True:\n",
    "    homeTeam = pd.get_dummies(games[\"teamHomeCode\"], prefix='hometeam').astype('bool')\n",
    "    awayTeam = pd.get_dummies(games[\"teamAwayCode\"], prefix='awayteam').astype('bool')\n",
    "\n",
    "    games = pd.concat([games, homeTeam, awayTeam], axis=1)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'hometeam_NYK', 'hometeam_CLE', 'awayteam_NYK', 'awayteam_CLE']].head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = games.drop([\"teamAwayCode\", \"teamHomeCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = games.drop([\"location\", \"scoreQuarters\", \"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = games.drop(statsColumns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games[\"homeWin\"] = games[\"scoreHome\"] > games[\"scoreAway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "games = games.drop([\"scoreAway\", \"scoreHome\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove any games that have less than a 5 game history.\n",
    "if calc_last_5_games == True:\n",
    "    games = games[(pd.notnull(games['lastGame1WinHome'])) & (pd.notnull(games['lastGame1AtHomeAway']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill any NaN stats with 0\n",
    "games.fillna(-13, inplace=True)\n",
    "#games['statsHome.Ejections'].fillna(0, inplace=True)\n",
    "#games['statsAway.Ejections'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>oddsBet365Away</th>\n",
       "      <th>oddsBet365Home</th>\n",
       "      <th>season</th>\n",
       "      <th>gamesPlayedHome</th>\n",
       "      <th>gamesPlayedAway</th>\n",
       "      <th>totalGamesHome</th>\n",
       "      <th>totalWinsHome</th>\n",
       "      <th>homeGamesHome</th>\n",
       "      <th>homeWinsHome</th>\n",
       "      <th>...</th>\n",
       "      <th>lastGame1AtHomeAway</th>\n",
       "      <th>lastGame2WinAway</th>\n",
       "      <th>lastGame2AtHomeAway</th>\n",
       "      <th>lastGame3WinAway</th>\n",
       "      <th>lastGame3AtHomeAway</th>\n",
       "      <th>lastGame4WinAway</th>\n",
       "      <th>lastGame4AtHomeAway</th>\n",
       "      <th>lastGame5WinAway</th>\n",
       "      <th>lastGame5AtHomeAway</th>\n",
       "      <th>homeWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, oddsBet365Away, oddsBet365Home, season, gamesPlayedHome, gamesPlayedAway, totalGamesHome, totalWinsHome, homeGamesHome, homeWinsHome, awayGamesHome, awayWinsHome, percentageTotalWinHome, percentageHomeWinHome, percentageAwayWinHome, totalGamesAway, totalWinsAway, homeGamesAway, homeWinsAway, awayGamesAway, awayWinsAway, percentageTotalWinAway, percentageHomeWinAway, percentageAwayWinAway, lastGame1WinHome, lastGame1AtHomeHome, lastGame2WinHome, lastGame2AtHomeHome, lastGame3WinHome, lastGame3AtHomeHome, lastGame4WinHome, lastGame4AtHomeHome, lastGame5WinHome, lastGame5AtHomeHome, lastGame1WinAway, lastGame1AtHomeAway, lastGame2WinAway, lastGame2AtHomeAway, lastGame3WinAway, lastGame3AtHomeAway, lastGame4WinAway, lastGame4AtHomeAway, lastGame5WinAway, lastGame5AtHomeAway, homeWin]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 45 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games[games.isnull().T.any().T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9068, 45)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train[\"homeWin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.drop([\"id\",\"homeWin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9068, 43)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jkentjnr/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685777287762\n",
      "0.692943770673\n",
      "0.656560088203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import  train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, Y_train, test_size=0.20, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=250)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import GPyOpt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "y=Y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = -cross_val_score(\n",
    "                XGBClassifier(learning_rate=parameters[0],\n",
    "                              max_depth=int(parameters[2]),\n",
    "                              n_estimators=int(parameters[3]),\n",
    "                              gamma=int(parameters[1]),\n",
    "                              min_child_weight = parameters[4]), \n",
    "                train, y, scoring='accuracy').mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "baseline = -cross_val_score(XGBClassifier(), train, y, scoring='accuracy').mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bounds = [\n",
    "            {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-5, 1)},\n",
    "            {'name': 'gamma', 'type': 'continuous', 'domain': (1e-5, 5)},\n",
    "            {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)},\n",
    "            {'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 2000)},\n",
    "            {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)}\n",
    "         ]\n",
    "\n",
    "np.random.seed(777)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds,\n",
    "                                                acquisition_type ='MPI',\n",
    "                                                acquisition_par = 0.1,\n",
    "                                                exact_eval=True)\n",
    "max_iter = 100\n",
    "max_time = 100\n",
    "optimizer.run_optimization(max_iter, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.683833349424396"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(optimizer.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "from sklearn.metrics import r2_score\n",
    "from __future__ import division\n",
    "import pandas as pd \n",
    "import  random as random\n",
    "import numpy as np\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import heapq\n",
    "from sklearn.linear_model import  LinearRegression,BayesianRidge\n",
    "from sklearn.ensemble import  RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import *\n",
    "import math\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import *\n",
    " \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    " \n",
    "class BadErrorTreshold(Exception):\n",
    "    pass\n",
    " \n",
    "class EnsembleClassifier(object):\n",
    "    ''''\n",
    "    ensembleClassifier is a class of ensembles generated by a  fix number of  iterations.This class is abstract \n",
    "    meaning  it  is not possible  to create instances  of it.,,stochasticLearning''  has interface  role. '''\n",
    "    def __init__(self,regressors,sampling,iterations,test,X,y,k_fold):\n",
    "        ''''intialize ensemble with  near all  parameters- see that   some of them are  intialized  by other methods'''\n",
    "        self.sampling=sampling#dropout(cv) ratio-percentage\n",
    "        if (self.sampling<=0.0 or self.sampling>=1.0):\n",
    "            raise ValueError('Sampling  must be percent like value between[0,1) ex 0.75, you introduced :',self.sampling)\n",
    " \n",
    " \n",
    "        self.test=test#final test set\n",
    "        self.X=X#original train features\n",
    "        self.y=y#original train outcome\n",
    "        self.iterations=iterations#number of  iterations in the  stochastic ensemble\n",
    "        self.regressors=regressors#ensemble models  for  each iteration      \n",
    "        self.randomIndexes=[ [] for rounds in range(self.iterations)]#filled in with random dropout  by getStochasticDataSets()\n",
    "        self.error=[]#error for  each averaged iteration\n",
    " \n",
    " \n",
    "        self.stochasticPredictions=[ [] for  rounds in range(self.iterations)]#predictions on random drop outs\n",
    "        self.finalPredictions=[]\n",
    " \n",
    "        self.x_train=[]#his   next  4 rows are intialized  by getStochasticDataSets() according to random chunks\n",
    "        self.y_train=[]\n",
    "        self.x_test=[]\n",
    "        self.y_test=[]\n",
    " \n",
    "        self.new_x_ts=[]\n",
    "        self.new_x_tr=[]\n",
    "        self.new_test_final=[]\n",
    "        self.k_folds=k_fold\n",
    "        \n",
    "    def returnError(self):\n",
    "        '''returns : error for  each iteration-just like cross-validation'''\n",
    "        return self.error\n",
    "    \n",
    "    def returnRandomIndexes(self):\n",
    "        '''returns: random  indexes  for  each dropout'''\n",
    "        return self.randomIndexes\n",
    "    \n",
    "    def returnstochasticPredictions(self):\n",
    "        '''returns:predictions  on random dropous'''\n",
    "        return self.stochasticPredictions\n",
    "    \n",
    "    def getStochasticDataSets(self):\n",
    "        '''\n",
    "        For some  potentially  iteration creates a random  idx variable representing the index  for random  dropout.\n",
    "        Splits the train in  train/test(x_train,y_train,features and outcome for cross val train-x_test,y_test for cross_val test\n",
    "        .Updated this train-test  variables with corresponding  values.See that  the initial vales are empty in the __init__.\n",
    "        returns: idx(index of  dropout rows).\n",
    "        \n",
    "        '''\n",
    "        x_train, x_test, y_train, y_test = train_test_split(self.X, self.y, test_size=self.sampling)\n",
    "        self.x_train=x_train\n",
    "        self.x_test=x_test\n",
    "        self.y_train=y_train\n",
    "        self.y_test=y_test\n",
    "        #train_i, test_i = train_test_split(np.arange(self.X.shape[0]), train_size = self.sampling)\n",
    "        #self.x_train=self.X[train_i]\n",
    "        #self.y_train=self.y[train_i]\n",
    "        #self.x_test=self.X[test_i]\n",
    "        #self.y_test=self.y[test_i]\n",
    "        #idx=test_i\n",
    "        #return  idx\n",
    "    \n",
    "    def training(self,i):\n",
    "        ''''\n",
    "        For a  particular iteration ,,i''  calls getStochasticDataSets() method.In this was the randomIndexes feature is\n",
    "        fiiled with corresponding index dropouts at position ,,i''.Since train/test new data sets according to cross validation\n",
    "        are   filled  by getStochasticDataSets()  independet  of iteration number , this data sets will update for each new iter.\n",
    "        performmed in stochasticLearning().'''\n",
    "        self.getStochasticDataSets()\n",
    "        #blending- we have x_train,y_train,x_test,y_test   our stochastic  dropouts for diversity\n",
    "        #we are  going first  to make blend train,blend test from this dropoutsthen will see evaluation on the dropout\n",
    "        clfs=self.regressors\n",
    "        n_folds=self.k_folds\n",
    "        skf=list(StratifiedKFold(self.y_train,n_folds))\n",
    "        blend_tr=np.zeros((self.x_train.shape[0],len(clfs)))\n",
    "        blend_ts=np.zeros((self.x_test.shape[0],len(clfs)))#for loca al evaluation\n",
    "        blend_final_test=np.zeros((self.test.shape[0],len(clfs)))\n",
    " \n",
    "        for  j , clf in  enumerate(clfs):\n",
    "            print(clf)\n",
    "            blend_ts_j=np.zeros((self.x_test.shape[0],len(skf)))\n",
    "            blend_final_j=np.zeros((self.test.shape[0],len(skf)))\n",
    "            for i ,(tr,ts) in enumerate(skf):\n",
    "                print(\"fold\",i)\n",
    "                x_tr=self.x_train[tr]\n",
    "                y_tr=self.y_train[tr]\n",
    "                x_ts=self.x_train[ts]\n",
    "                y_ts=self.y_train[ts]\n",
    "                clf.fit(x_tr,y_tr)\n",
    "                y_sub=clf.predict_proba(x_ts)[:,1]\n",
    "                blend_tr[ts,j]=y_sub\n",
    "                blend_ts_j[:,i]=clf.predict_proba(self.x_test)[:,1]\n",
    "                blend_final_j[:,i]=clf.predict_proba(self.test)[:,1]\n",
    "            blend_ts[:,j]=blend_ts_j.mean(1)\n",
    "            blend_final_test[:,j]=blend_final_j.mean(1)\n",
    "        #blend on evaluation\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(blend_tr, self.y_train)\n",
    "        \n",
    "        pred_eval=  clf.predict_proba(blend_ts)[:,1]\n",
    "        self.error.append(log_loss(self.y_test,pred_eval))\n",
    "        #blend  on final test set:\n",
    "        final_sub=clf.predict_proba(blend_final_test)[:,1]\n",
    "        self.finalPredictions.append(final_sub)\n",
    "        \n",
    "        \n",
    " \n",
    "        return self\n",
    "    \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "       raise NotImplementedError###averages models  according to best top prediction  trehsold  with different implementantions\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    def stochasticLearning(self):\n",
    "         raise NotImplementedError#Since EnsemebleRegressors class is abstract this will act  as an interface\n",
    "                                  #and will be implemented   by  this  EnsembleClassifier sublclasses  for averaging and\n",
    "                                  #weighted average\n",
    "    \n",
    "        \n",
    "class AveragingModels(EnsembleClassifier):\n",
    "    '''Inherits everything from EnsembleRegressors  class and implements stochastiLearning method  averaging models \n",
    "    for each iteration'''\n",
    " \n",
    "    def stochasticLearning(self):\n",
    "        \n",
    "        \n",
    "        for iter in range(self.iterations):\n",
    "            print('Stochastic Iteration number ',iter)\n",
    "            self.training(iter)\n",
    " \n",
    "    def getFinalPrediction(self,errorTreshold):\n",
    "        if (errorTreshold<=self.iterations and errorTreshold>0):\n",
    "            \n",
    "            topErrorIndex=heapq.nsmallest(errorTreshold, range(len(self.error)), self.error.__getitem__)\n",
    "            finalAvg=0\n",
    "            for topError in topErrorIndex:\n",
    "                finalAvg=finalAvg+self.finalPredictions[topError]\n",
    "            finalAvg=(finalAvg)/float(len(topErrorIndex))\n",
    "            return finalAvg\n",
    "        else:\n",
    "            raise BadErrorTreshold\n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

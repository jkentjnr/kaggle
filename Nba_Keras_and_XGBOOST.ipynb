{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import geopy.distance\n",
    "\n",
    "#package for flattening json in pandas df\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_last_5_games = True\n",
    "calc_win_loss = True\n",
    "calc_win_loss_write_all = True\n",
    "use_team_keys = False\n",
    "use_team_hot_encoding = False\n",
    "use_team_home_away_hot_encoding = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load games - json object\n",
    "with open('games.json') as gamesJsonRaw:\n",
    "    d = json.load(gamesJsonRaw)\n",
    "\n",
    "games = json_normalize(d['games'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stadiums.json') as stadiumsJsonRaw:\n",
    "    stadiumsJson = json.load(stadiumsJsonRaw)\n",
    "\n",
    "stadiums = json_normalize(stadiumsJson['stadiums'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#games['season'] = games['season'].astype('float')\n",
    "games['scoreAway'] = games['scoreAway'].astype('uint8')\n",
    "games['scoreHome'] = games['scoreHome'].astype('uint8')\n",
    "games['teamAwayId'] = games['teamAwayId'].astype('uint8')\n",
    "games['teamHomeId'] = games['teamHomeId'].astype('uint8')\n",
    "\n",
    "#scoreQuarters          object\n",
    "#teamAwayCode           object\n",
    "#teamHomeCode           object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a dataframe for the results - same size as dataset\n",
    "data = pd.DataFrame(index=range(0,len(games)), columns=['gamesPlayedHome', 'gamesPlayedAway'])\n",
    "\n",
    "# Iterate through every team\n",
    "for team in games.teamAwayCode.unique():\n",
    "    gameCount = 0\n",
    "    homeGameCount = 0;\n",
    "    \n",
    "    # Iterate through each game the team is present in.\n",
    "    for index, game in games[(games['teamAwayCode'] == team) | (games['teamHomeCode'] == team)].iterrows():\n",
    "        gameCount += 1\n",
    "        \n",
    "        # Update game count for team - whether away or home.\n",
    "        if game.teamAwayCode == team:\n",
    "            data.loc[index]['gamesPlayedAway'] = gameCount\n",
    "        else:\n",
    "            data.loc[index]['gamesPlayedHome'] = gameCount\n",
    "\n",
    "data['gamesPlayedAway'] = data['gamesPlayedAway'].astype('uint8')\n",
    "data['gamesPlayedHome'] = data['gamesPlayedHome'].astype('uint8')\n",
    "            \n",
    "# Append the results to the dataset\n",
    "games = pd.merge(games, data, left_index=True, right_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamHomeCode</th>\n",
       "      <th>teamAwayCode</th>\n",
       "      <th>gamesPlayedHome</th>\n",
       "      <th>gamesPlayedAway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>CHI</td>\n",
       "      <td>SAC</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>DAL</td>\n",
       "      <td>ORL</td>\n",
       "      <td>54</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>CHA</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>GSW</td>\n",
       "      <td>MIA</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>NYK</td>\n",
       "      <td>CLE</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    teamHomeCode teamAwayCode  gamesPlayedHome  gamesPlayedAway\n",
       "656          CHI          SAC               45               43\n",
       "810          DAL          ORL               54               56\n",
       "26           CHA          BOS                3                3\n",
       "574          GSW          MIA               39               40\n",
       "755          NYK          CLE               52               49"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games[['teamHomeCode', 'teamAwayCode', 'gamesPlayedHome', 'gamesPlayedAway']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calc_percentage(x, y):\n",
    "    return 0 if y == 0 else x / y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gingasu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:23: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/gingasu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:26: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/gingasu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:52: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "/home/gingasu/.local/lib/python2.7/site-packages/ipykernel_launcher.py:55: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    }
   ],
   "source": [
    "if calc_win_loss == True:\n",
    "    \n",
    "    # Create a dataframe for the results - same size as dataset\n",
    "    data = pd.DataFrame(\n",
    "        index=range(0,len(games)), \n",
    "        columns=[\n",
    "            'totalGamesHome', 'totalWinsHome', 'homeGamesHome', 'homeWinsHome', 'awayGamesHome', 'awayWinsHome',\n",
    "            'percentageTotalWinHome', 'percentageHomeWinHome', 'percentageAwayWinHome',\n",
    "            'totalGamesAway', 'totalWinsAway', 'homeGamesAway', 'homeWinsAway', 'awayGamesAway', 'awayWinsAway',\n",
    "            'percentageTotalWinAway', 'percentageHomeWinAway', 'percentageAwayWinAway'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Iterate through each game.\n",
    "    for index, game in games.iterrows():\n",
    "\n",
    "        # Home Team\n",
    "        # ---------\n",
    "        \n",
    "        historicGames = games[(games['gamesPlayedHome'] < game.gamesPlayedHome) & ((games['teamHomeCode'] == game.teamHomeCode) | (games['teamAwayCode'] == game.teamHomeCode))].sort_values(by='gamesPlayedHome', ascending=True)\n",
    "       \n",
    "        homeGamesHome = len(historicGames[(historicGames['teamHomeCode'] == game['teamHomeCode'])])        \n",
    "        homeWinsHome = len(historicGames[(historicGames['teamHomeCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] < games[\"scoreHome\"])])\n",
    "        \n",
    "        awayGamesHome = len(historicGames[(historicGames['teamAwayCode'] == game['teamHomeCode'])])        \n",
    "        awayWinsHome = len(historicGames[(historicGames['teamAwayCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] > games[\"scoreHome\"])])\n",
    "\n",
    "        #totalGames = len(historicGames);\n",
    "        #totalWins = len(\n",
    "        #    historicGames[\n",
    "        #        (historicGames['teamHomeCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] < games[\"scoreHome\"]) |\n",
    "        #        (historicGames['teamAwayCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] > games[\"scoreHome\"])\n",
    "        #    ]\n",
    "        #)\n",
    "        \n",
    "        totalGamesHome = homeGamesHome + awayGamesHome\n",
    "        totalWinsHome = homeWinsHome + awayWinsHome\n",
    "        \n",
    "        percentageTotalWinHome = round(calc_percentage(totalWinsHome, totalGamesHome), 3)\n",
    "        percentageHomeWinHome = round(calc_percentage(homeWinsHome, homeGamesHome), 3)\n",
    "        percentageAwayWinHome = round(calc_percentage(awayWinsHome, awayGamesHome), 3)\n",
    "        \n",
    "        # print('HOME', game['gamesPlayedHome'], 'TG', totalGamesHome, 'W', totalWinsHome, 'HGP', homeGamesHome, 'HW', homeWinsHome, 'AGP', awayGamesHome, 'AW', awayWinsHome)\n",
    "        # print('HOME', 'W%', percentageTotalWinHome, 'HW%', percentageHomeWinHome, 'AW%', percentageAwayWinHome)\n",
    "        \n",
    "        # Away Team\n",
    "        # ---------\n",
    "        \n",
    "        historicGames = games[(games['gamesPlayedAway'] < game.gamesPlayedAway) & ((games['teamAwayCode'] == game.teamAwayCode) | (games['teamHomeCode'] == game.teamAwayCode))].sort_values(by='gamesPlayedAway', ascending=True)\n",
    "       \n",
    "        homeGamesAway = len(historicGames[(historicGames['teamHomeCode'] == game['teamAwayCode'])])        \n",
    "        homeWinsAway = len(historicGames[(historicGames['teamHomeCode'] == game['teamAwayCode']) & (games[\"scoreAway\"] < games[\"scoreHome\"])])\n",
    "        \n",
    "        awayGamesAway = len(historicGames[(historicGames['teamAwayCode'] == game['teamAwayCode'])])        \n",
    "        awayWinsAway = len(historicGames[(historicGames['teamAwayCode'] == game['teamAwayCode']) & (games[\"scoreAway\"] > games[\"scoreHome\"])])\n",
    "\n",
    "        #totalGames = len(historicGames);\n",
    "        #totalWins = len(\n",
    "        #    historicGames[\n",
    "        #        (historicGames['teamHomeCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] < games[\"scoreHome\"]) |\n",
    "        #        (historicGames['teamAwayCode'] == game['teamHomeCode']) & (games[\"scoreAway\"] > games[\"scoreHome\"])\n",
    "        #    ]\n",
    "        #)\n",
    "        \n",
    "        totalGamesAway = homeGamesAway + awayGamesAway\n",
    "        totalWinsAway = homeWinsAway + awayWinsAway\n",
    "        \n",
    "        percentageTotalWinAway = round(calc_percentage(totalWinsAway, totalGamesAway), 3)\n",
    "        percentageHomeWinAway = round(calc_percentage(homeWinsAway, homeGamesAway), 3)\n",
    "        percentageAwayWinAway = round(calc_percentage(awayWinsAway, awayGamesAway), 3)\n",
    "        \n",
    "        # print('AWAY', game['gamesPlayedAway'], 'TG', totalGamesAway, 'W', totalWinsAway, 'HGP', homeGamesAway, 'HW', homeWinsAway, 'AGP', awayGamesAway, 'AW', awayWinsAway)\n",
    "        # print('AWAY', 'W%', percentageTotalWinAway, 'HW%', percentageHomeWinAway, 'AW%', percentageAwayWinAway)\n",
    "        \n",
    "        # ---------    \n",
    "            \n",
    "        # Update the row with the history\n",
    "        data.loc[index] = [\n",
    "            totalGamesHome, totalWinsHome, homeGamesHome, homeWinsHome, awayGamesHome, awayWinsHome,\n",
    "            percentageTotalWinHome, percentageHomeWinHome, percentageAwayWinHome,\n",
    "            totalGamesAway, totalWinsAway, homeGamesAway, homeWinsAway, awayGamesAway, awayWinsAway,\n",
    "            percentageTotalWinAway, percentageHomeWinAway, percentageAwayWinAway\n",
    "        ]\n",
    "\n",
    "    # Add results to the dataset\n",
    "    if (calc_win_loss_write_all == True):\n",
    "        games = pd.merge(games, data, left_index=True, right_index=True)\n",
    "        games[['teamHomeCode', 'teamAwayCode', 'percentageTotalWinHome', 'percentageHomeWinHome', 'percentageAwayWinHome', 'percentageTotalWinAway', 'percentageHomeWinAway', 'percentageAwayWinAway']].sample(5)\n",
    "    else:\n",
    "        games = pd.merge(games, data[['percentageHomeWinHome', 'percentageAwayWinAway']], left_index=True, right_index=True)\n",
    "        games[['teamHomeCode', 'teamAwayCode', 'percentageHomeWinHome', 'percentageAwayWinAway']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_last_5_games == True:\n",
    "    \n",
    "    # Create a dataframe for the results - same size as dataset\n",
    "    data = pd.DataFrame(index=range(0,len(games)), columns=['lastGame1WinHome', 'lastGame1AtHomeHome', 'lastGame2WinHome', 'lastGame2AtHomeHome', 'lastGame3WinHome', 'lastGame3AtHomeHome', 'lastGame4WinHome', 'lastGame4AtHomeHome', 'lastGame5WinHome', 'lastGame5AtHomeHome'])\n",
    "\n",
    "    # Iterate through each game where the teams have played at least 5 games.\n",
    "    for index, game in games.iterrows():\n",
    "\n",
    "        # Get the last five games for the team.\n",
    "        last5games = games[(games['gamesPlayedHome'] < game.gamesPlayedHome) & ((games['teamAwayCode'] == game.teamHomeCode) | (games['teamHomeCode'] == game.teamHomeCode))].sort_values(by='gamesPlayedHome', ascending=False).head(5)\n",
    "\n",
    "        if len(last5games) == 5:\n",
    "            lastGame1WinHome = last5games[\"scoreAway\"].iloc[0] < last5games[\"scoreHome\"].iloc[0]\n",
    "            lastGame2WinHome = last5games[\"scoreAway\"].iloc[1] < last5games[\"scoreHome\"].iloc[1]\n",
    "            lastGame3WinHome = last5games[\"scoreAway\"].iloc[2] < last5games[\"scoreHome\"].iloc[2]\n",
    "            lastGame4WinHome = last5games[\"scoreAway\"].iloc[3] < last5games[\"scoreHome\"].iloc[3]\n",
    "            lastGame5WinHome = last5games[\"scoreAway\"].iloc[4] < last5games[\"scoreHome\"].iloc[4]\n",
    "            #print(lastGame1WinHome, lastGame2WinHome, lastGame3WinHome, lastGame4WinHome, lastGame5WinHome)\n",
    "\n",
    "            lastGame1AtHomeHome = last5games[\"teamHomeCode\"].iloc[0] == game.teamHomeCode\n",
    "            lastGame2AtHomeHome = last5games[\"teamHomeCode\"].iloc[1] == game.teamHomeCode\n",
    "            lastGame3AtHomeHome = last5games[\"teamHomeCode\"].iloc[2] == game.teamHomeCode\n",
    "            lastGame4AtHomeHome = last5games[\"teamHomeCode\"].iloc[3] == game.teamHomeCode\n",
    "            lastGame5AtHomeHome = last5games[\"teamHomeCode\"].iloc[4] == game.teamHomeCode\n",
    "            #print(lastGame1AtHomeHome, lastGame2AtHomeHome, lastGame3AtHomeHome, lastGame4AtHomeHome, lastGame5AtHomeHome)\n",
    "\n",
    "            # Update the row with the history\n",
    "            data.loc[index] = [lastGame1WinHome, lastGame1AtHomeHome, lastGame2WinHome, lastGame2AtHomeHome, lastGame3WinHome, lastGame3AtHomeHome, lastGame4WinHome, lastGame4AtHomeHome, lastGame5WinHome, lastGame5AtHomeHome]\n",
    "\n",
    "    # Convert types \n",
    "    data['lastGame1WinHome'] = data['lastGame1WinHome'].astype('bool')\n",
    "    data['lastGame2WinHome'] = data['lastGame2WinHome'].astype('bool')\n",
    "    data['lastGame3WinHome'] = data['lastGame3WinHome'].astype('bool')\n",
    "    data['lastGame4WinHome'] = data['lastGame4WinHome'].astype('bool')\n",
    "    data['lastGame5WinHome'] = data['lastGame5WinHome'].astype('bool')\n",
    "    data['lastGame1AtHomeHome'] = data['lastGame1AtHomeHome'].astype('bool')\n",
    "    data['lastGame2AtHomeHome'] = data['lastGame2AtHomeHome'].astype('bool')\n",
    "    data['lastGame3AtHomeHome'] = data['lastGame3AtHomeHome'].astype('bool')\n",
    "    data['lastGame4AtHomeHome'] = data['lastGame4AtHomeHome'].astype('bool')\n",
    "    data['lastGame5AtHomeHome'] = data['lastGame5AtHomeHome'].astype('bool')\n",
    "\n",
    "    # Add results to the dataset\n",
    "    games = pd.merge(games, data, left_index=True, right_index=True)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'lastGame1WinHome', 'lastGame1AtHomeHome', 'lastGame2WinHome', 'lastGame2AtHomeHome', 'lastGame3WinHome', 'lastGame3AtHomeHome', 'lastGame4WinHome', 'lastGame4AtHomeHome', 'lastGame5WinHome', 'lastGame5AtHomeHome']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calc_last_5_games == True:\n",
    "    \n",
    "    # Create a dataframe for the results - same size as dataset\n",
    "    data = pd.DataFrame(index=range(0,len(games)), columns=['lastGame1WinAway', 'lastGame1AtHomeAway', 'lastGame2WinAway', 'lastGame2AtHomeAway', 'lastGame3WinAway', 'lastGame3AtHomeAway', 'lastGame4WinAway', 'lastGame4AtHomeAway', 'lastGame5WinAway', 'lastGame5AtHomeAway'])\n",
    "\n",
    "    # Iterate through each game where the teams have played at least 5 games.\n",
    "    for index, game in games.iterrows():\n",
    "\n",
    "        # Get the last five games for the team.\n",
    "        last5games = games[(games['gamesPlayedAway'] < game.gamesPlayedAway) & ((games['teamAwayCode'] == game.teamAwayCode) | (games['teamHomeCode'] == game.teamAwayCode))].sort_values(by='gamesPlayedAway', ascending=False).head(5)\n",
    "\n",
    "        if len(last5games) == 5:\n",
    "            lastGame1WinAway = last5games[\"scoreAway\"].iloc[0] < last5games[\"scoreHome\"].iloc[0]\n",
    "            lastGame2WinAway = last5games[\"scoreAway\"].iloc[1] < last5games[\"scoreHome\"].iloc[1]\n",
    "            lastGame3WinAway = last5games[\"scoreAway\"].iloc[2] < last5games[\"scoreHome\"].iloc[2]\n",
    "            lastGame4WinAway = last5games[\"scoreAway\"].iloc[3] < last5games[\"scoreHome\"].iloc[3]\n",
    "            lastGame5WinAway = last5games[\"scoreAway\"].iloc[4] < last5games[\"scoreHome\"].iloc[4]\n",
    "            #print(lastGame1WinAway, lastGame2WinAway, lastGame3WinAway, lastGame4WinAway, lastGame5WinAway)\n",
    "\n",
    "            lastGame1AtHomeAway = last5games[\"teamAwayCode\"].iloc[0] == game.teamAwayCode\n",
    "            lastGame2AtHomeAway = last5games[\"teamAwayCode\"].iloc[1] == game.teamAwayCode\n",
    "            lastGame3AtHomeAway = last5games[\"teamAwayCode\"].iloc[2] == game.teamAwayCode\n",
    "            lastGame4AtHomeAway = last5games[\"teamAwayCode\"].iloc[3] == game.teamAwayCode\n",
    "            lastGame5AtHomeAway = last5games[\"teamAwayCode\"].iloc[4] == game.teamAwayCode\n",
    "            #print(lastGame1AtHomeAway, lastGame2AtHomeAway, lastGame3AtHomeAway, lastGame4AtHomeAway, lastGame5AtHomeAway)\n",
    "\n",
    "            # Update the row with the history\n",
    "            data.loc[index] = [lastGame1WinAway, lastGame1AtHomeAway, lastGame2WinAway, lastGame2AtHomeAway, lastGame3WinAway, lastGame3AtHomeAway, lastGame4WinAway, lastGame4AtHomeAway, lastGame5WinAway, lastGame5AtHomeAway]\n",
    "\n",
    "    # Convert types         \n",
    "    data['lastGame1WinAway'] = data['lastGame1WinAway'].astype('bool')\n",
    "    data['lastGame2WinAway'] = data['lastGame2WinAway'].astype('bool')\n",
    "    data['lastGame3WinAway'] = data['lastGame3WinAway'].astype('bool')\n",
    "    data['lastGame4WinAway'] = data['lastGame4WinAway'].astype('bool')\n",
    "    data['lastGame5WinAway'] = data['lastGame5WinAway'].astype('bool')\n",
    "    data['lastGame1AtHomeAway'] = data['lastGame1AtHomeAway'].astype('bool')\n",
    "    data['lastGame2AtHomeAway'] = data['lastGame2AtHomeAway'].astype('bool')\n",
    "    data['lastGame3AtHomeAway'] = data['lastGame3AtHomeAway'].astype('bool')\n",
    "    data['lastGame4AtHomeAway'] = data['lastGame4AtHomeAway'].astype('bool')\n",
    "    data['lastGame5AtHomeAway'] = data['lastGame5AtHomeAway'].astype('bool')\n",
    "\n",
    "    # Add results to the dataset\n",
    "    games = pd.merge(games, data, left_index=True, right_index=True)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'lastGame1WinHome', 'lastGame1AtHomeHome', 'lastGame2WinHome', 'lastGame2AtHomeHome', 'lastGame3WinHome', 'lastGame3AtHomeHome', 'lastGame4WinHome', 'lastGame4AtHomeHome', 'lastGame5WinHome', 'lastGame5AtHomeHome']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337.6783477035342"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test entry for stadium distance calc\n",
    "\n",
    "coords_1 = (37.750267, -122.202853)\n",
    "coords_2 = (34.04303865743706, -118.26711416244507)\n",
    "\n",
    "geopy.distance.vincenty(coords_1, coords_2).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"time\"] = pd.to_datetime(games[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_team_hot_encoding == True:\n",
    "    homeTeam = pd.get_dummies(games[\"teamHomeCode\"], prefix='team')\n",
    "    awayTeam = pd.get_dummies(games[\"teamAwayCode\"], prefix='team')\n",
    "\n",
    "    homeTeam = homeTeam.replace({0:np.nan})\n",
    "    awayTeam = awayTeam.replace({0:np.nan})\n",
    "\n",
    "    teams = homeTeam.fillna(awayTeam).fillna(0).astype('bool')\n",
    "    # teams[['team_NYK', 'team_CLE', 'team_ATL', 'team_BOS']].head(2)\n",
    "    \n",
    "    games = pd.concat([games, teams], axis=1)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'team_NYK', 'team_CLE']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_team_home_away_hot_encoding == True:\n",
    "    homeTeam = pd.get_dummies(games[\"teamHomeCode\"], prefix='hometeam').astype('bool')\n",
    "    awayTeam = pd.get_dummies(games[\"teamAwayCode\"], prefix='awayteam').astype('bool')\n",
    "\n",
    "    games = pd.concat([games, homeTeam, awayTeam], axis=1)\n",
    "    \n",
    "    games[['teamHomeCode', 'teamAwayCode', 'hometeam_NYK', 'hometeam_CLE', 'awayteam_NYK', 'awayteam_CLE']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (use_team_hot_encoding == True) | (use_team_home_away_hot_encoding == True) | (use_team_keys == False):\n",
    "    games = games.drop([\"teamAwayId\", \"teamHomeId\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.drop([\"teamAwayCode\", \"teamHomeCode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.drop([\"location\", \"scoreQuarters\", \"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "games[\"homeWin\"] = games[\"scoreHome\"] > games[\"scoreAway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "games = games.drop([\"scoreAway\", \"scoreHome\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Remove any games that have less than a 5 game history.\n",
    "if calc_last_5_games == True:\n",
    "    games = games[(pd.notnull(games['lastGame1WinHome'])) & (pd.notnull(games['lastGame1AtHomeAway']))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>oddsBet365Away</th>\n",
       "      <th>oddsBet365Home</th>\n",
       "      <th>season</th>\n",
       "      <th>gamesPlayedHome</th>\n",
       "      <th>gamesPlayedAway</th>\n",
       "      <th>totalGamesHome</th>\n",
       "      <th>totalWinsHome</th>\n",
       "      <th>homeGamesHome</th>\n",
       "      <th>homeWinsHome</th>\n",
       "      <th>...</th>\n",
       "      <th>lastGame1AtHomeAway</th>\n",
       "      <th>lastGame2WinAway</th>\n",
       "      <th>lastGame2AtHomeAway</th>\n",
       "      <th>lastGame3WinAway</th>\n",
       "      <th>lastGame3AtHomeAway</th>\n",
       "      <th>lastGame4WinAway</th>\n",
       "      <th>lastGame4AtHomeAway</th>\n",
       "      <th>lastGame5WinAway</th>\n",
       "      <th>lastGame5AtHomeAway</th>\n",
       "      <th>homeWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, oddsBet365Away, oddsBet365Home, season, gamesPlayedHome, gamesPlayedAway, totalGamesHome, totalWinsHome, homeGamesHome, homeWinsHome, awayGamesHome, awayWinsHome, percentageTotalWinHome, percentageHomeWinHome, percentageAwayWinHome, totalGamesAway, totalWinsAway, homeGamesAway, homeWinsAway, awayGamesAway, awayWinsAway, percentageTotalWinAway, percentageHomeWinAway, percentageAwayWinAway, lastGame1WinHome, lastGame1AtHomeHome, lastGame2WinHome, lastGame2AtHomeHome, lastGame3WinHome, lastGame3AtHomeHome, lastGame4WinHome, lastGame4AtHomeHome, lastGame5WinHome, lastGame5AtHomeHome, lastGame1WinAway, lastGame1AtHomeAway, lastGame2WinAway, lastGame2AtHomeAway, lastGame3WinAway, lastGame3AtHomeAway, lastGame4WinAway, lastGame4AtHomeAway, lastGame5WinAway, lastGame5AtHomeAway, homeWin]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 45 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games[games.isnull().T.any().T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msk = np.random.rand(len(games)) < 0.8\n",
    "#msk\n",
    "\n",
    "train = games\n",
    "#test = games[~msk]\n",
    "\n",
    " \n",
    "temp=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "for col in  train.columns:\n",
    "    \n",
    "    if train[col].dtype=='object' or  train[col].dtype=='bool':\n",
    "        train[col]=le.fit_transform(train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train = train[\"homeWin\"]\n",
    "X_train = train.drop([\"id\",\"homeWin\"], axis=1)\n",
    "X=np.array(X_train)\n",
    "y=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import xgboost  as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=xgb.XGBClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(np.array(X),y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  matplotlib\n",
    "from matplotlib  import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ##########################################Checking accuracy  on  5 cross   validations###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=250)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=cross)\n",
    "    model=RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=model\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), indices)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import GPy\n",
    "import GPyOpt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "y=y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def f(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = -cross_val_score(\n",
    "                XGBClassifier(learning_rate=parameters[0],\n",
    "                              max_depth=int(parameters[2]),\n",
    "                              n_estimators=int(parameters[3]),\n",
    "                              gamma=int(parameters[1]),\n",
    "                              min_child_weight = parameters[4]), \n",
    "                X, y, scoring='accuracy').mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "baseline = -cross_val_score(XGBClassifier(), X, y, scoring='accuracy').mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [\n",
    "            {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-5, 1)},\n",
    "            {'name': 'gamma', 'type': 'continuous', 'domain': (1e-5, 5)},\n",
    "            {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 50)},\n",
    "            {'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 1000)},\n",
    "            {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)}\n",
    "         ]\n",
    "\n",
    "np.random.seed(777)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds,\n",
    "                                                acquisition_type ='MPI',\n",
    "                                                acquisition_par = 0.1,\n",
    "                                                exact_eval=True)\n",
    "max_iter = 50\n",
    "max_time = 60\n",
    "optimizer.run_optimization(max_iter, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer.plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "optimizer.X[np.argmin(optimizer.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(optimizer.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=1000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "                           max_depth= 50,min_child_weight=10)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "xgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################Adding  new features ############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################correlation###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train=pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train1=np.hstack((new_train,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp_train1, y, test_size=0.33, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=1000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "                           max_depth= 50,min_child_weight=10)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=10, n_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train=svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train2=np.hstack((new_train,temp_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp_train2, y, test_size=0.33, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=1000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "                           max_depth= 50,min_child_weight=10)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = TSNE(n_components=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(new_train[:,0],new_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train3=np.hstack((new_train,X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp_train3, y, test_size=0.33, random_state=cross)\n",
    "    model=xgb.XGBClassifier(n_estimators=1000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "                           max_depth= 50,min_child_weight=10)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier\n",
    "for cross  in range(5):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(temp_train3, y, test_size=0.33, random_state=cross)\n",
    "    model=RandomForestClassifier(n_estimators=500)\n",
    "    model.fit(X_train,y_train)\n",
    "    pred=model.predict(X_test)\n",
    "    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_training_predictors = pd.get_dummies(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 626)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoded_training_predictors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train=one_hot_encoded_training_predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train= big_train.drop([\"id\",\"homeWin\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 624)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for cross  in range(5):\n",
    "#    X_train, X_test, y_train, y_test = train_test_split(big_train, y, test_size=0.2, random_state=cross)\n",
    "#    model=xgb.XGBClassifier(n_estimators=5000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "#                           max_depth= 200,min_child_weight=10)\n",
    "#    model.fit(X_train,y_train)\n",
    "#    pred=model.predict(X_test)\n",
    "#    print(accuracy_score(y_test,pred))\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.60898316937410624"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def f(parameters):\n",
    "    parameters = parameters[0]\n",
    "    score = -cross_val_score(\n",
    "                XGBClassifier(learning_rate=parameters[0],\n",
    "                              max_depth=int(parameters[2]),\n",
    "                              n_estimators=int(parameters[3]),\n",
    "                              gamma=int(parameters[1]),\n",
    "                              min_child_weight = parameters[4]), \n",
    "                X, y, scoring='accuracy').mean()\n",
    "    score = np.array(score)\n",
    "    return score\n",
    "baseline = -cross_val_score(XGBClassifier(), big_train, y, scoring='accuracy').mean()\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = [\n",
    "            {'name': 'learning_rate', 'type': 'continuous', 'domain': (1e-5, 1)},\n",
    "            {'name': 'gamma', 'type': 'continuous', 'domain': (1e-5, 5)},\n",
    "            {'name': 'max_depth', 'type': 'discrete', 'domain': (1, 200)},\n",
    "            {'name': 'n_estimators', 'type': 'discrete', 'domain': (1, 5000)},\n",
    "            {'name': 'min_child_weight', 'type': 'discrete', 'domain': (1, 10)}\n",
    "         ]\n",
    "\n",
    "np.random.seed(777)\n",
    "optimizer = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds,\n",
    "                                                acquisition_type ='MPI',\n",
    "                                                acquisition_par = 0.1,\n",
    "                                                exact_eval=True)\n",
    "max_iter = 50\n",
    "max_time = 60\n",
    "optimizer.run_optimization(max_iter, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.62928861075236497"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(optimizer.Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0.35028689,     4.88600234,   200.        ,  5000.        ,\n",
       "          10.        ])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "optimizer.X[np.argmin(optimizer.Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dense, Dropout, Convolution1D, Flatten, MaxPooling1D,BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 624)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def create_baseline():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(128, input_dim=624, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    " \n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    " \n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.2))\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "      \n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.09))\n",
    "    \n",
    "    model.add(Dense(16, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(32, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(Dropout(0.15))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(64, kernel_initializer='normal', activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Dense(128, input_dim=624, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 56.08% (6.40%)\n"
     ]
    }
   ],
   "source": [
    " \n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "results = cross_val_score(estimator, np.array(big_train), y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################Averaging   first   attempt######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 43)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "    model1=xgb.XGBClassifier(n_estimators=1000,learning_rate=0.33589572,gamma=4.8989112,\n",
    "                           max_depth= 50,min_child_weight=10)\n",
    "    model2=RandomForestClassifier(n_estimators=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=4.8989112, learning_rate=0.33589572,\n",
       "       max_delta_step=0, max_depth=50, min_child_weight=10, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=250, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1=model1.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg=(pred1+pred2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63008130081300817"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics  import log_loss\n",
    "accuracy_score(y_test,np.round(avg[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "damian=big_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "damian['y']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "damian.to_csv('NBA_DATA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_train=big_train.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
